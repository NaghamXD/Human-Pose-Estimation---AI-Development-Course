{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the data folder containing the images\n",
    "data_folder = r\"C:\\Users\\Nagham\\HRNet-Human-Pose-Estimation\\data\\hr-lspet1\"  # Replace with the actual path to your image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotation file\n",
    "#annotations = scipy.io.loadmat(r\"C:\\Users\\Nagham\\HRNet-Human-Pose-Estimation\\data\\hr-lspet\\joints.mat\")\n",
    "# Load the MATLAB file\n",
    "annotations = scipy.io.loadmat(os.path.join(data_folder, 'joints.mat'))\n",
    "joints = annotations['joints']  # Shape will be (3, 14, N), where N is the number of images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of joints: <class 'numpy.ndarray'>\n",
      "Shape of joints: (14, 3, 9428)\n"
     ]
    }
   ],
   "source": [
    "# Check the type and shape of the joints array\n",
    "print(\"Type of joints:\", type(joints))\n",
    "print(\"Shape of joints:\", joints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints for the first image:\n",
      " [[156  82 169 220 145  91 420 359 304 330 360 422 325 375]\n",
      " [248 279 234 280 292 300  68 106 146 227 284 279 166 170]\n",
      " [  0   1   1   1   1   1   1   1   1   1   1   1   1   1]]\n"
     ]
    }
   ],
   "source": [
    "# Example: Extract keypoints for the first image\n",
    "keypoints_first_image = joints[:, :, 3817].T  # Extract x and y coordinates and transpose to get shape (14, 2)\n",
    "print(\"Keypoints for the first image:\\n\", keypoints_first_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints for the first image:\n",
      " [[156 248   0]\n",
      " [ 82 279   1]\n",
      " [169 234   1]\n",
      " [220 280   1]\n",
      " [145 292   1]\n",
      " [ 91 300   1]\n",
      " [420  68   1]\n",
      " [359 106   1]\n",
      " [304 146   1]\n",
      " [330 227   1]\n",
      " [360 284   1]\n",
      " [422 279   1]\n",
      " [325 166   1]\n",
      " [375 170   1]]\n"
     ]
    }
   ],
   "source": [
    "# Example: Extract keypoints for the first image\n",
    "keypoints_first_image = joints[:, :, 0]  # Extract x and y coordinates and the visibility tag\n",
    "print(\"Keypoints for the first image:\\n\", keypoints_first_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(keypoints, padding=0):\n",
    "    \"\"\"\n",
    "    Calculate the bounding box for a given set of keypoints.\n",
    "    \n",
    "    Parameters:\n",
    "    keypoints (array-like): An array of keypoints with shape (N, 2), where N is the number of keypoints.\n",
    "    padding (int): Optional padding to add around the bounding box.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: The coordinates of the bounding box (x_min, y_min, x_max, y_max).\n",
    "    \"\"\"\n",
    "    keypoints = np.array(keypoints)\n",
    "    x_min = np.min(keypoints[:, 0])\n",
    "    x_max = np.max(keypoints[:, 0])\n",
    "    y_min = np.min(keypoints[:, 1])\n",
    "    y_max = np.max(keypoints[:, 1])\n",
    "    \n",
    "    # Add padding\n",
    "    x_min -= padding\n",
    "    x_max += padding\n",
    "    y_min -= padding\n",
    "    y_max += padding\n",
    "    \n",
    "    return x_min, y_min, x_max, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example keypoints for a single person\n",
    "keypoints = joints[:, :, 0]  # Extract x and y coordinates and the visibility tag\n",
    "\n",
    "# Calculate the bounding box with a padding of 5 pixels\n",
    "bounding_box = get_bounding_box(keypoints, padding=5)\n",
    "\n",
    "print(\"Bounding Box Coordinates:\", bounding_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(joints.shape[2]):\n",
    "    keypoints = joints[:, :2, i]  # Extract keypoints for the i-th image and transpose to get shape (14, 2)\n",
    "    bounding_box = get_bounding_box(keypoints, padding=5)\n",
    "    print(f\"Image {i+1} Bounding Box: {bounding_box}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(image, bbox, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Draw a bounding box on the image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: The image on which to draw.\n",
    "    - bbox: A tuple (x_min, y_min, x_max, y_max) representing the bounding box.\n",
    "    - color: The color of the bounding box.\n",
    "    - thickness: The thickness of the bounding box lines.\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image file names\n",
    "#image_files = [f'im{i+1:05d}.jpg' for i in range(joints.shape[2])]  # Assuming images are named as 'im0001.jpg', 'im0002.jpg', etc.\n",
    "# Load the image file names\n",
    "image_files = [os.path.join(data_folder, f'im{i+1:05d}.png') for i in range(10)]  # Assuming images are named as 'im0001.jpg', 'im0002.jpg', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the images with bounding boxes\n",
    "for i, image_file in enumerate(image_files):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for displaying with Matplotlib\n",
    "    \n",
    "    # Get the keypoints for the current image\n",
    "    keypoints = joints[:, :2, i]  # Extract x and y coordinates and transpose to get shape (14, 2)\n",
    "    \n",
    "    # Calculate the bounding box\n",
    "    bbox = get_bounding_box(keypoints, padding=15)\n",
    "    \n",
    "    # Draw the bounding box on the image\n",
    "    image_with_bbox = draw_bounding_box(image, bbox)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image_with_bbox)\n",
    "    plt.title(f'Image {i+1} with Bounding Box')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-trained Faster R-CNN model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Define image transformations\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the images with bounding boxes\n",
    "for i, image_file in enumerate(image_files):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for displaying with Matplotlib\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image_tensor)\n",
    "\n",
    "    # Extract relevant information from predictions\n",
    "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "    labels = predictions[0]['labels'].cpu().numpy()\n",
    "    scores = predictions[0]['scores'].cpu().numpy()\n",
    "    \n",
    "  # COCO dataset class ID for \"person\" is 1\n",
    "    PERSON_CLASS_ID = 1\n",
    "  # Set a confidence threshold\n",
    "    confidence_threshold = 0.5\n",
    "\n",
    "    # Filter boxes for humans with scores above the threshold\n",
    "    human_boxes = [box for box, label, score in zip(boxes, labels, scores) if label == PERSON_CLASS_ID and score > confidence_threshold]\n",
    "\n",
    "    \n",
    "    # Plot the image and draw the bounding boxes\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for box in human_boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        width, height = xmax - xmin, ymax - ymin\n",
    "        rect = plt.Rectangle((xmin, ymin), width, height, fill=False, color='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
